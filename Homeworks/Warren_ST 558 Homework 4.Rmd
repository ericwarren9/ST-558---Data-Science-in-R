---
title: "ST 558 Homework 4"
author: "Eric Warren"
date: '2023-09-21'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
    theme: readable
    df_print: tibble
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Part 1 - Some Concept Questions

1. The path I would need to specify in order to get the file located at `myfolder/MyData.csv` would be "~/myfolder/MyData.csv". We cannot just do "MyData.csv" because our working directory is different from where this csv file is stored so if we read it in using this option we will get an error saying the file does not exist.

2. Using R Projects has some benefits. Each R Project has its own working directory, workspace, history, and source documents. This makes it easier to organize all documents and files needed when completing a task and allows us to use the relative paths for reading files in when organized in this way. This makes our code more reproducible to other users (where absolute paths would cause the user to have to make changes). In other words, it has all files that we generate in the same place. So all data, code, plots, reports, etc. are altogether in one place without having to manage the files separately. 

3. Git is a version control software to help track changes we commit to files and allows multiple users to work on the same project. GitHub is a hosting service that allows git-based projects on the internet and makes it easy to share such projects.

# Part 2 - Reading in Delimited Data

## Glass Data

1. Here we are going to read in our `glass_data` and do some manipulations to it. After looking at the ![Glass Data](https://www4.stat.ncsu.edu/~online/datasets/glass.data), we can see that this is comma delimited so we should use the `read_csv()` function from the `tidyverse` library.
```{r read in glass data}
library(tidyverse)
col_names <- c("Id", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe", "Type_of_glass")
glass_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/glass.data", col_names = col_names)
glass_data
```

2. We are going to overwrite the `Type_of_glass` variable by creating a `factor` here instead. We are going to use the variable descriptions above to give meaningful factor levels.
```{r making factors for glass data}
levels <- c(1, 2, 3, 5, 6, 7)
labels <- c("building_windows_float_processed", "building_windows_non_float_processed", "vehicle_windows_float_processed", "containers", "tableware", "headlamps")
glass_data$Type_of_glass <- factor(glass_data$Type_of_glass, levels = levels, labels = labels)
```

3. Print the data frame with only observations where the `Fe` variable is less than 0.2 and the `Type_of_glass` is either tableware or headlamp.
```{r print filtered df}
glass_data %>%
  filter((Fe < 0.2) & (Type_of_glass %in% c("tableware", "headlamps")))
```

## Yeast Data

1. Here we are going to read in our `yeast_data` and do some manipulations to it. After looking at the ![Yeast Data](https://www4.stat.ncsu.edu/~online/datasets/yeast.data), we can see that this is a tab delimited file (in the form of a table) so we should use the `read_table()` function from the `tidyverse` library.
```{r read in yeast data}
col_names2 <- c("seq_name", "mcg", "gvh", "alm", "mit", "erl", "pox", "vac", "nuc", "class")
yeast_data <- read_table("https://www4.stat.ncsu.edu/~online/datasets/yeast.data", col_names = col_names2)
yeast_data
```

2. Select only the `class` and `mcg` columns. Report the mean and standard deviation of the `mcg` value for each setting of the `class` variable. We will use the `summarize()` function to do this.
```{r summarize yeast}
yeast_data %>%
  select(mcg, class) %>%
  group_by(class) %>%
  summarize(mean = mean(mcg),
            sd = sd(mcg))
```

# Part 3 - Database

We are now working with `SQLite` by using a database called `chinook`. This database has tables of songs, playlists, customers, invoices, and more. 

1. First we are going to download the `chinook.db` database. We will also need to load in the `DBI` and `RSQLite` libraries and use `tidyverse` from before. We are going to use the `dbConnect()` function to connect to the local database.
```{r load in database}
# Load in libraries needed
library(DBI)
library(RSQLite)

# Connect to database
con <- DBI::dbConnect(RSQLite::SQLite(), "chinook.db")
```

2. Now we will print out the tables in the database using `dbListTables()`.
```{r print tables in database}
dbListTables(con)
```

3. Use `dbGetQuery()` or `tbl()` to grab and print out the `invoices` table and the `customers` table.
```{r grab needed tables from database}
# Invoices table
chinook_invoices <- tbl(con, "invoices")
chinook_invoices

# Customers table
chinook_customers <- tbl(con, "customers")
chinook_customers
```

4. Use an `inner_join()` to combine the two tables above by the `CustomerID` variable
```{r combine tables from database}
chinook_data <- inner_join(chinook_invoices, chinook_customers, by = "CustomerId")
chinook_data
```

# Part 4 - Querying an API

For this section we will connect to the news API we connected to in our lecture. We will need to go to to ![newsapi.org](https://newsapi.org).

1. Use `GET` from the `httr` package to return information about a topic of interest from the news lately. With our free account we can only find information from the past 30 days.
```{r news api topic returned}
library(httr)
api_data <- httr::GET("https://newsapi.org/v2/top-headlines?country=us&category=business&apiKey=30f54a89a7db4753887e12893d5b3afc")
```

2. Find our way to the data frame that has the actual article information in it. This time, save that R object. Select only the `source`, `author`, and `title` columns and print the tibble out.
```{r print news api}
library(jsonlite)
# Parse to the content from the api
parsed <- fromJSON(rawToChar(api_data$content))

# Get the data frame and save it
data_frame_api <- parsed$articles

# Print this new data frame out with selected columns
data_frame_api %>%
  as_tibble() %>%
  select(source, author, title)
```